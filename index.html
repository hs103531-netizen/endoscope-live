<!doctype html>
<html lang="ko">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Endoscope AI (WebGPU/WASM)</title>
  <style>
    body{font-family:system-ui,Arial,sans-serif;margin:16px;background:#f7fafc}
    .row{display:flex;gap:12px;flex-wrap:wrap;align-items:flex-start}
    video,canvas{border:1px solid #ddd;border-radius:10px}
    #panel{display:flex;gap:12px;align-items:center;margin:8px 0}
    .card{background:#fff;border:1px solid #e2e8f0;border-radius:10px;padding:10px;min-width:120px}
    .k{font-size:12px;color:#64748b} .v{font-size:18px;font-weight:600}
    button{border:0;background:#2563eb;color:#fff;padding:8px 12px;border-radius:8px;cursor:pointer}
    button#stop{background:#ef4444}
  </style>
</head>
<body>
<h2>Endoscope AI – Browser Inference</h2>

<div class="row">
  <video id="cam" autoplay playsinline style="width:480px"></video>
  <canvas id="view" width="640" height="640"></canvas>
</div>

<div id="panel">
  <button id="start">Start</button>
  <button id="stop">Stop</button>
  <div class="card"><div class="k">FPS</div><div class="v" id="fpsVal">0</div></div>
  <div class="card"><div class="k">Latency(ms)</div><div class="v" id="latVal">0</div></div>
  <div class="card"><div class="k">Conf(%)</div><div class="v" id="confVal">0</div></div>
  <div class="card"><div class="k">Conn</div><div class="v" id="connVal">대기중</div></div>
</div>

<script>
  // === Hugging Face 직링크 (resolve) ===
  const MODEL_URL_FP32 = "https://huggingface.co/jdi1009/endoscope-assets/resolve/main/inference_model.onnx";
  const LABELS_URL     = "https://huggingface.co/jdi1009/endoscope-assets/resolve/main/labels.json";
  // FP16은 일단 비워두고 FP32만 사용해서 안정화
  //const MODEL_URL_FP16 = ""; // 나중에 필요하면 실제 링크로 채우기

  // 안정 모드: WASM 고정
  const INPUT_W=640, INPUT_H=640, MEAN=[0.485,0.456,0.406], STD=[0.229,0.224,0.225];
  const CONF_TH=0.35, NMS_IOU=0.5, TOPK=100;
  const LOAD_TIMEOUT_MS = 45000;

  // ★ onnxruntime 전역 이름과 충돌 방지: 우리 쪽은 ORT 별칭 사용
  let ORT = null, session = null, labels = ["object"];

  function loadScript(src){return new Promise((res,rej)=>{const s=document.createElement('script');s.src=src;s.onload=res;s.onerror=rej;document.head.appendChild(s);});}
  async function ensureORT(){
    // WASM 번들만 로드(안정)
    await loadScript("https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js");
    ORT = window.ort;
    return ORT;
  }

  function softmax(a){const m=Math.max(...a);const e=a.map(v=>Math.exp(v-m));const s=e.reduce((x,y)=>x+y,0);return e.map(v=>v/s)}
  function cxcywh2xyxy(b,W=INPUT_W,H=INPUT_H){const[cx,cy,w,h]=b;return[(cx-w/2)*W,(cy-h/2)*H,(cx+w/2)*W,(cy+h/2)*H]}
  function iou(a,b){const[ax1,ay1,ax2,ay2]=a,[bx1,by1,bx2,by2]=b;const ix1=Math.max(ax1,bx1),iy1=Math.max(ay1,by1);
    const ix2=Math.min(ax2,bx2),iy2=Math.min(ay2,by2);const iw=Math.max(0,ix2-ix1),ih=Math.max(0,iy2-iy1);
    const inter=iw*ih;const u=(ax2-ax1)*(ay2-ay1)+(bx2-bx1)*(by2-by1)-inter+1e-6;return inter/u}
  function nms(d,thr=NMS_IOU){d.sort((a,b)=>b.score-a.score);const keep=[];for(const x of d){let ok=true;for(const y of keep){if(iou(x.xyxy,y.xyxy)>thr){ok=false;break}}if(ok)keep.push(x)}return keep}

  const cam=document.getElementById('cam'), canvas=document.getElementById('view'), ctx=canvas.getContext('2d');
  const fpsEl=document.getElementById('fpsVal'), latEl=document.getElementById('latVal'), confEl=document.getElementById('confVal'), connEl=document.getElementById('connVal');
  const startBtn=document.getElementById('start'), stopBtn=document.getElementById('stop');

  // 버튼은 먼저 연결(카메라 미리 켜짐)
  let running=false, raf=0, last=performance.now(), emaFps=0;
  startBtn.onclick = async ()=>{
    if(running) return;
    const stream = await navigator.mediaDevices.getUserMedia({video:{facingMode:'environment'}, audio:false});
    cam.srcObject = stream; await cam.play();
    connEl.textContent = session ? '연결됨' : '연결됨(모델 로딩중)';
    running = true; raf = requestAnimationFrame(loop);
  };
  stopBtn.onclick = ()=>{
    running=false; cancelAnimationFrame(raf);
    cam.srcObject?.getTracks()?.forEach(t=>t.stop());
    ctx.clearRect(0,0,canvas.width,canvas.height);
    connEl.textContent='연결끊김'; fpsEl.textContent='0'; latEl.textContent='0'; confEl.textContent='0';
  };

  function preprocess(video){
    const W=INPUT_W, H=INPUT_H;
    const useOff = typeof OffscreenCanvas!=='undefined';
    const cv = useOff ? new OffscreenCanvas(W,H) : (function(){const c=document.createElement('canvas'); c.width=W; c.height=H; return c;})();
    const o = cv.getContext('2d',{willReadFrequently:true});
    o.drawImage(video,0,0,W,H);
    const {data}=o.getImageData(0,0,W,H);
    const hw=W*H, arr=new Float32Array(3*hw);
    for(let i=0;i<hw;i++){const r=data[i*4]/255,g=data[i*4+1]/255,b=data[i*4+2]/255;
      arr[i]=(r-MEAN[0])/STD[0]; arr[i+hw]=(g-MEAN[1])/STD[1]; arr[i+2*hw]=(b-MEAN[2])/STD[2];}
    return new ORT.Tensor('float32',arr,[1,3,H,W]);
  }

  async function loop(t){
    const t0=performance.now();
    if(!session){
      ctx.drawImage(cam,0,0,canvas.width,canvas.height);
      latEl.textContent='-';
      if(running) raf=requestAnimationFrame(loop);
      return;
    }
    const feeds={}; feeds[session.inputNames?session.inputNames[0]:'images']=preprocess(cam);
    const out=await session.run(feeds);
    const names=Object.keys(out);
    const logitsT=out[names.find(n=>n.toLowerCase().includes('logit'))||names[0]];
    const boxesT =out[names.find(n=>n.toLowerCase().includes('box'))  ||names[1]];
    const logits=Array.from(logitsT.data), boxes=Array.from(boxesT.data);

    const Q=boxes.length/4, C=logits.length/Q, dets=[]; let maxScore=0;
    for(let q=0;q<Math.min(Q,TOPK);q++){
      const probs=softmax(logits.slice(q*C,q*C+C)); const bg=C-1; probs[bg]=-1;
      let best=0,idx=0; for(let i=0;i<C-1;i++){ if(probs[i]>best){ best=probs[i]; idx=i; } }
      if(best<CONF_TH) continue;
      const xyxy=cxcywh2xyxy(boxes.slice(q*4,q*4+4), canvas.width, canvas.height);
      dets.push({xyxy,label:labels[idx]??String(idx),score:best}); if(best>maxScore) maxScore=best;
    }
    const final=nms(dets,NMS_IOU);

    ctx.drawImage(cam,0,0,canvas.width,canvas.height);
    ctx.lineWidth=2; ctx.font='14px system-ui';
    for(const d of final){
      const [x1,y1,x2,y2]=d.xyxy; ctx.strokeStyle='#18a058'; ctx.strokeRect(x1,y1,x2-x1,y2-y1);
      const tag=`${d.label} ${d.score.toFixed(2)}`; 
      const tw=ctx.measureText(tag).width+6;
      ctx.fillStyle='rgba(24,160,88,0.9)'; ctx.fillRect(x1,Math.max(0,y1-18),tw,18);
      ctx.fillStyle='#fff'; ctx.fillText(tag,x1+3,Math.max(12,y1-4));
    }

    const lat=performance.now()-t0; latEl.textContent=lat.toFixed(1);
    const dt=t-last; last=t; const fps=1000/dt; emaFps=emaFps?emaFps*0.9+fps*0.1:fps; fpsEl.textContent=emaFps.toFixed(1);
    confEl.textContent=(maxScore*100).toFixed(1);
    if(running) raf=requestAnimationFrame(loop);
  }

  // === 백그라운드 로딩 (WASM 고정 + 경로 명시 + 타임아웃) ===
  (async ()=>{
    try{
      const timeout = new Promise((_,rej)=>setTimeout(()=>rej(new Error('timeout')), LOAD_TIMEOUT_MS));
      await ensureORT();
      // WASM 파일 경로 명시(중요)
      ORT.env.wasm.wasmPaths = "https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/";
      ORT.env.wasm.numThreads = 1;
      ORT.env.wasm.simd = true;

      try{ labels = await fetch(LABELS_URL).then(r=>r.json()); }catch(e){ console.warn('labels.json load fail', e); }

      connEl.textContent='모델 로딩중';
      // EP는 wasm만(안정)
      const createPromise = ORT.InferenceSession.create(MODEL_URL_FP32, { executionProviders:['wasm'], graphOptimizationLevel:'all' });
      session = await Promise.race([createPromise, timeout]);

      connEl.textContent='준비됨';
    }catch(e){
      console.error(e);
      connEl.textContent = (e?.message==='timeout') ? '모델 로딩 실패(네트워크/용량)' : '모델 로딩 실패';
    }
  })();
</script>

</body>
</html>
